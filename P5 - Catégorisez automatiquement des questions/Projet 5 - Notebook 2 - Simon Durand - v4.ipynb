{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f0222a",
   "metadata": {},
   "source": [
    "# <font color=\"#114b98\">Catégorisez automatiquement des questions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815ab77",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\">Notebook de test de différents modèles</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb1151",
   "metadata": {},
   "source": [
    "**Stack Overflow** est un site célèbre de questions-réponses liées au développement informatique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d05297",
   "metadata": {},
   "source": [
    "L'objectif de ce projet est de développer un système de **suggestion de tags** pour ce site. Celui-ci prendra la forme d’un algorithme de machine learning qui assignera automatiquement plusieurs tags pertinents à une question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25dcf2",
   "metadata": {},
   "source": [
    "**Livrable** : Un notebook de test de différents modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378bec4",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\">Sommaire</font>\n",
    "[1. Chargement du jeu de données](#section_1)\n",
    "\n",
    "[2. Approche non supervisée](#section_2)\n",
    "\n",
    "[3. Approche supervisée](#section_3)\n",
    "\n",
    "[4. Approche supervisée avec Word Embedding : Word2Vec](#section_4)\n",
    "\n",
    "[5. Approche supervisée avec Word Embedding : BERT](#section_5)\n",
    "\n",
    "[6. Approche supervisée avec Sentence Embedding : USE](#section_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb45a8",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_1\">1. Chargement du jeu de données</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import ast\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ed41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=22) \n",
    "plt.rc('axes', labelsize=18) \n",
    "titleprops = {'fontsize':20}\n",
    "textprops = {'fontsize':15}\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'N:/5 - WORK/1 - Projets/Projet 5/'\n",
    "files = os.listdir(main_path+'saved_ressources/')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a251077",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(main_path+'saved_ressources/'+'data_cleaned.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.applymap(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d34fa",
   "metadata": {},
   "source": [
    "Le jeu de données est trop important pour les temps de calculs à ma disposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ffd4f",
   "metadata": {},
   "source": [
    "J'ai deux possibilités : \n",
    "- prendre un sample de 5000 observations aléatoirement\n",
    "- prendre les 5000 observations pour lesquelles la similarité entre les deux colonnes est importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7568d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sample = data.sample(5000)\n",
    "# data_sample.reset_index(inplace=True, drop=True)\n",
    "# print(data_sample.shape)\n",
    "# data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d247c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1: List[str], list2: List[str]) -> float:\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    jaccard_similarity = len(intersection) / len(union)\n",
    "    return jaccard_similarity\n",
    "\n",
    "def get_highest_similarity_rows(data: pd.DataFrame, col1: str, col2: str, n: int):\n",
    "    data[\"jaccard_similarity\"] = data.apply(lambda x: jaccard_similarity(x[col1], x[col2]), axis=1)\n",
    "    data = data.sort_values(by=\"jaccard_similarity\", ascending=False)\n",
    "    return data.head(n)\n",
    "\n",
    "\n",
    "data_sample = get_highest_similarity_rows(data, \"Tags\", \"Texts\", 1000)\n",
    "data_sample.drop(['jaccard_similarity'], axis=1, inplace=True)\n",
    "data_sample.reset_index(inplace=True, drop=True)\n",
    "print(data_sample.shape)\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = data_sample[\"Texts\"].to_list()\n",
    "tags_list = data_sample[\"Tags\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721078cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_texts = [\" \".join(text) for text in texts_list]\n",
    "flat_tags = [\" \".join(tag) for tag in tags_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b05e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_texts = list(set([word for item in texts_list for word in item]))\n",
    "vocabulary_tags = list(set([word for item in tags_list for word in item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2b074",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_2\">2. Approche non supervisée</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import Nmf\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8eb174",
   "metadata": {},
   "source": [
    "LDA (Latent Dirichlet Allocation) est une technique de topic modeling qui permet de découvrir les thèmes cachés (ou \"latents\") dans un ensemble de textes. Elle permet de regrouper des textes qui traitent des mêmes sujets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea29ec",
   "metadata": {},
   "source": [
    "La classe LdaModel de gensim est basée sur l'algorithme d'allocation latente de Dirichlet (LDA), qui est un modèle probabiliste génératif utilisé pour découvrir les sujets cachés dans un corpus de textes. La classe LatentDirichletAllocation de scikit-learn est également basée sur l'algorithme LDA, mais elle peut avoir des différences en termes d'implémentation, comme l'algorithme d'optimisation utilisé ou les paramètres disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea0e17",
   "metadata": {},
   "source": [
    "NMF (Non-negative Matrix Factorization) est une autre technique de topic modeling qui permet de décomposer une matrice document-terme en deux matrices de facteurs non-négatifs. Elle est souvent utilisée pour découvrir les thèmes cachés dans des textes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96332ae",
   "metadata": {},
   "source": [
    "La classe gensim Nmf est basée sur l'algorithme de factorisation de matrice non-négative, qui est différente de la classe NMF de scikit-learn, qui est basée sur la méthode de gradient projeté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35595bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_optimal_num_topics(data, vectorizer, n_topics_range, texts_list):\n",
    "    \"\"\"\n",
    "    Given data, a vectorizer, a range of number of topics to test, and the list of texts,\n",
    "    applies the models to the data and plots the silhouette and coherence scores to help \n",
    "    determine the optimal number of topics.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Vectorize the data\n",
    "    data = vectorizer.fit_transform(data)\n",
    "    dictionary = Dictionary(texts_list)\n",
    "    corpus = [dictionary.doc2bow(txt) for txt in texts_list]\n",
    "\n",
    "    # Initialize lists to store scores for LDA and NMF\n",
    "    lda_scores = []\n",
    "    nmf_scores = []\n",
    "    coherence_nmf = []\n",
    "    coherence_lda = []\n",
    "\n",
    "    # Loop through the range of number of topics\n",
    "    for n_topics in n_topics_range:\n",
    "        \n",
    "        # Calculate the silhouette score for the LDA model\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, max_iter=300)\n",
    "        lda.fit(data)\n",
    "        topic_assignments = lda.transform(data)\n",
    "        labels = np.argmax(topic_assignments, axis=1)\n",
    "        lda_scores.append(silhouette_score(topic_assignments, labels, metric='euclidean'))\n",
    "        \n",
    "        # Calculate the silhouette score for the NMF model\n",
    "        nmf = NMF(n_components=n_topics, max_iter=300)\n",
    "        nmf.fit(data)\n",
    "        topic_assignments = nmf.transform(data)\n",
    "        labels = np.argmax(topic_assignments, axis=1)\n",
    "        nmf_scores.append(silhouette_score(topic_assignments, labels, metric='euclidean'))\n",
    "        \n",
    "        # Calculate the coherence score for the LDA model\n",
    "        lda = LdaModel(corpus, num_topics=n_topics, id2word=dictionary)\n",
    "        cm_lda = CoherenceModel(model=lda, texts=texts_list, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_lda.append(cm_lda.get_coherence())\n",
    "            \n",
    "        # Calculate the coherence score for the NMF model\n",
    "        nmf = Nmf(corpus, num_topics=n_topics, id2word=dictionary)\n",
    "        cm_nmf = CoherenceModel(model=nmf, texts=texts_list, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_nmf.append(cm_nmf.get_coherence())\n",
    "     \n",
    "    scores = pd.DataFrame(columns=['topics_silhouette',\n",
    "                                   'score_silhouette',\n",
    "                                   'topics_coherence',\n",
    "                                   'score_coherence'], \n",
    "                          index=['LDA', 'NMF'])\n",
    "\n",
    "    scores['topics_silhouette'] = [n_topics_range[np.argmax(lda_scores)], n_topics_range[np.argmax(nmf_scores)]]\n",
    "    scores['score_silhouette'] = [max(lda_scores), max(nmf_scores)]\n",
    "    scores['topics_coherence'] = [n_topics_range[np.argmax(coherence_lda)], n_topics_range[np.argmax(coherence_nmf)]]\n",
    "    scores['score_coherence'] = [max(coherence_lda), max(coherence_nmf)]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    plt.suptitle('Silhouette and Coherence Scores for LDA and NMF with {}'.format(str(vectorizer).split('(')[0]))\n",
    "    \n",
    "    ax1.plot(n_topics_range, lda_scores, label='LDA')\n",
    "    ax1.plot(n_topics_range, nmf_scores, label='NMF')\n",
    "    ax1.set_xlabel('Number of Topics')\n",
    "    ax1.set_ylabel('Silhouette score')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(n_topics_range, coherence_lda, label='LDA')\n",
    "    ax2.plot(n_topics_range, coherence_nmf, label='NMF')\n",
    "    ax2.set_xlabel('Number of Topics')\n",
    "    ax2.set_ylabel('Coherence score')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21431fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of number of topics to test\n",
    "n_topics_range = range(2, 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537d01f",
   "metadata": {},
   "source": [
    "CountVectorizer() est une implémentation de l'approche bag-of-words pour la vectorisation de textes. Il convertit un ensemble de documents en un tableau de compte de mots (ou un sac de mots), où chaque ligne représente un document et chaque colonne représente un mot. Le nombre dans chaque cellule est le nombre de fois où le mot correspondant est présent dans le document correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dfba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09910832",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_and_lda_models_with_CountVectorizer = determine_optimal_num_topics(flat_texts, vectorizer, n_topics_range, texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8734e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_and_lda_models_with_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a118024",
   "metadata": {},
   "source": [
    "TF-IDF (term frequency-inverse document frequency) est une technique utilisée pour pondérer les termes dans les textes en fonction de leur fréquence d'apparition. Elle permet de donner plus de poids aux termes qui apparaissent fréquemment dans un document mais rarement dans l'ensemble des documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd433b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(vocabulary=vocabulary_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_and_lda_models_with_TfidfVectorizer= determine_optimal_num_topics(flat_texts, vectorizer, n_topics_range, texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959aea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_and_lda_models_with_TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9623f",
   "metadata": {},
   "source": [
    "Le score de silhouette mesure la similarité d'un objet à son propre groupe par rapport aux autres groupes et généralement, plus il est proche de 1, meilleure est la classification. Le score de cohérence mesure à quel point les sujets sont \"interprétables par les humains\", généralement plus proche de 1, meilleur c'est."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1adfb6d",
   "metadata": {},
   "source": [
    "Dans notre situation, lorsque le nombre de sujets augmente, ils sont plus \"interprétables par les humains\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a1e69",
   "metadata": {},
   "source": [
    "Nous devons maintenant essayer d'obtenir des tags en utilisatn ces méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f318a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a244f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051ab7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad5da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e26ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4287900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b65b6e3",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_3\">3. Approche supervisée</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfec925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, jaccard_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18dac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e581924",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_mlb = mlb.fit_transform(flat_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(random_state=42, max_iter=300, tol=1e-5),\n",
    "               SGDClassifier(random_state=42, max_iter=300, tol=1e-5),\n",
    "               RandomForestClassifier(random_state=42),\n",
    "               KNeighborsClassifier(),\n",
    "               MultinomialNB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ebb7d",
   "metadata": {},
   "source": [
    " - Accuracy: mesure de combien de prédictions faites par le modèle sont correctes\n",
    " - Precision: mesure combien des prédictions positives faites par le modèle sont effectivement correctes. Un score de précision élevé signifie que le modèle fait peu de prédictions positives fausses.\n",
    " - Recall: mesure combien des exemples positifs réels sont correctement prédits par le modèle. Un score de rappel élevé signifie que le modèle est capable de trouver la plupart des exemples positifs.\n",
    " - F1 Score: mesure de l'exactitude d'un modèle, il est un moyen harmonique de précision et de rappel. Il varie de 0 à 1, où un score proche de 1 indique une meilleure performance et un score proche de 0 indique une performance moins bonne. \n",
    " - Jaccard Score: mesure de la similarité entre les deux ensembles de prédictions et de vraies étiquettes. Il varie de 0 à 1, où un score proche de 1 indique une très grande similitude et un score proche de 0 indique une grande dissimilarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_supervised_scores(flat_texts, tags_mlb, vectorizer, classifiers):\n",
    "    \n",
    "    # Create an empty dataframe to store the results\n",
    "    results_df = pd.DataFrame(columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Jaccard Score'])\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(flat_texts, tags_mlb, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Vectorize X_train and X_test\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Fit an independent model for each class using the OneVsRestClassifier wrapper.\n",
    "    for classifier in classifiers:\n",
    "        ovrc = OneVsRestClassifier(classifier)\n",
    "        ovrc.fit(X_train, y_train)\n",
    "        y_pred_ovrc = ovrc.predict(X_test)\n",
    "        \n",
    "        accuracy = round(accuracy_score(y_test, y_pred_ovrc), 4)\n",
    "        precision = round(precision_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        recall = round(recall_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        f1 = round(f1_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        jaccard = round(jaccard_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        \n",
    "        results_df = results_df.append({'Classifier': str(classifier).split('(')[0], \n",
    "                                       'Accuracy': accuracy, \n",
    "                                       'Precision': precision, \n",
    "                                       'Recall': recall, \n",
    "                                       'F1 Score': f1, \n",
    "                                       'Jaccard Score': jaccard}, \n",
    "                                       ignore_index=True)\n",
    "                                       \n",
    "        print('Results for classifier:', classifier)\n",
    "        print(\"Accuracy : \", accuracy)\n",
    "        print(\"Precision : \", precision)\n",
    "        print(\"Recall : \", recall)\n",
    "        print(\"F1 Score : \", f1)\n",
    "        print(\"Jaccard Score:\", jaccard)\n",
    "        print('\\n')\n",
    "        \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5fbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_CountVectorizer = calculate_supervised_scores(flat_texts, tags_mlb, vectorizer, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa632ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results_df):\n",
    "    \n",
    "    # Create a figure with 5 subplots\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20,5))\n",
    "    \n",
    "    # Set a color palette\n",
    "    my_palette = sns.color_palette(\"husl\", 5)\n",
    "    \n",
    "    # Set the x-axis to be a range of numerical values\n",
    "    x = range(len(results_df))\n",
    "    scoring_methods = ['Accuracy','Precision','Recall','F1 Score','Jaccard Score']\n",
    "    \n",
    "    # Create a bar plot for each subplot\n",
    "    sns.barplot(x='Classifier', y='Accuracy', data=results_df, ax=axs[0], palette=my_palette, label='Accuracy')\n",
    "    sns.barplot(x='Classifier', y='Precision', data=results_df, ax=axs[1], palette=my_palette, label='Precision')\n",
    "    sns.barplot(x='Classifier', y='Recall', data=results_df, ax=axs[2], palette=my_palette, label='Recall')\n",
    "    sns.barplot(x='Classifier', y='F1 Score', data=results_df, ax=axs[3], palette=my_palette, label='F1 Score')\n",
    "    sns.barplot(x='Classifier', y='Jaccard Score', data=results_df, ax=axs[4], palette=my_palette, label='Jaccard Score')\n",
    "    \n",
    "    # Add classifier names to x-axis\n",
    "    for i in range(5):\n",
    "        axs[i].set_xticks(x)\n",
    "        axs[i].set_xticklabels(results_df['Classifier'], rotation=90)\n",
    "        axs[i].set_xlabel('Classifier')\n",
    "        axs[i].set_ylabel('Score')\n",
    "        axs[i].set_title(scoring_methods[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plot_results function\n",
    "plot_results(results_df_CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4730005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(vocabulary=vocabulary_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_TfidfVectorizer = calculate_supervised_scores(flat_texts, tags_mlb, vectorizer, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plot_results function\n",
    "plot_results(results_df_TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6aede",
   "metadata": {},
   "source": [
    "Le RandomForestClassifier obtient les meilleurs scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cdc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fjzseimflhqiseflehqsflqehzs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bbff03",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_4\">4. Approche supervisée avec Word Embedding : Word2Vec</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_t = [word_tokenize(sent) for text in flat_texts for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bf494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Word2Vec model on the text data\n",
    "model = Word2Vec(texts_t, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature vectors for the text data by averaging the word vectors\n",
    "X = []\n",
    "for text in texts_t:\n",
    "    feature_vec = np.zeros(100)\n",
    "    n_words = 0\n",
    "    for word in text:\n",
    "        if word in model.wv:\n",
    "            feature_vec = np.add(feature_vec, model.wv[word])\n",
    "            n_words += 1\n",
    "    if n_words > 0:\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    X.append(feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8bb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, flat_tags, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a naive bayes classifier on the training data, and make predictions on the test data\n",
    "start_time = time.time()\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time taken: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's accuracy\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e2729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ccdd5b",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_5\">5. Approche supervisée avec Word Embedding : BERT</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a27ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26daaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertTokenizer\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d511854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3db60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the text data as input for the BERT model\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "for text in flat_texts:\n",
    "    encoded_text = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, pad_to_max_length=True)\n",
    "    input_ids.append(encoded_text[\"input_ids\"])\n",
    "    attention_masks.append(encoded_text[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to PyTorch tensors\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "labels = torch.tensor(flat_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_ids, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdf78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the training set\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    TensorDataset(X_train, y_train),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816adf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer and scheduler for fine-tuning the BERT model\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88fd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the BERT model on the training data\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        input_ids, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        loss = criterion(outputs[0], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ec0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = model(X_test, attention_mask=attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ee2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the logits to predictions\n",
    "test_preds = torch.argmax(test_logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's accuracy on the test data\n",
    "print(accuracy_score(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468cac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bddef9c4",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_6\">6. Approche supervisée avec Sentence Embedding : USE</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609096ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dff51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the USE model\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the text data as input for the USE model\n",
    "X = use_model(flat_texts).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, flat_tags, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087229b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier on the encoded text data\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(np.unique(flat_tags)), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac18a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47764990",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9537692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9014119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's accuracy on the test data\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055932cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
