{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f0222a",
   "metadata": {},
   "source": [
    "# <font color=\"#114b98\">Catégorisez automatiquement des questions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815ab77",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\">Notebook de test de différents modèles</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb1151",
   "metadata": {},
   "source": [
    "**Stack Overflow** est un site célèbre de questions-réponses liées au développement informatique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d05297",
   "metadata": {},
   "source": [
    "L'objectif de ce projet est de développer un système de **suggestion de tags** pour ce site. Celui-ci prendra la forme d’un algorithme de machine learning qui assignera automatiquement plusieurs tags pertinents à une question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25dcf2",
   "metadata": {},
   "source": [
    "**Livrable** : Un notebook de test de différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c6190",
   "metadata": {},
   "source": [
    "**Objectifs** : Comparer les modèles et générer des tags pour chacun d'entre eux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378bec4",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\">Sommaire</font>\n",
    "[1. Chargement du jeu de données](#section_1)\n",
    "\n",
    "[2. Approche non supervisée](#section_2)\n",
    "\n",
    "[3. Approche supervisée](#section_3)\n",
    "\n",
    "[4. Approche supervisée avec Word Embedding : Word2Vec](#section_4)\n",
    "\n",
    "[5. Approche supervisée avec Word Embedding : BERT](#section_5)\n",
    "\n",
    "[6. Approche supervisée avec Sentence Embedding : USE](#section_6)\n",
    "\n",
    "[7. Choix du modèle pour le code final à déployer](#section_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb45a8",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_1\">1. Chargement du jeu de données</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf8947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import ast\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fb8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext pycodestyle_magic\n",
    "# %pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0ed41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=22)\n",
    "plt.rc('axes', labelsize=18)\n",
    "titleprops = {'fontsize':20}\n",
    "textprops = {'fontsize':15}\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b96f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'N:/5 - WORK/1 - Projets/Projet 5/'\n",
    "data = pd.read_csv(main_path+'saved_ressources/'+'data_cleaned.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2fe98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Texts\"] = data[\"Texts\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c144b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tags\"] = data[\"Tags\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0fd42dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[javascript, jquery, string, date, object]</td>\n",
       "      <td>[jquery, javascript, convert, date, string, da...</td>\n",
       "      <td>jquery javascript convert date string date hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vba, excel, function, size, byte]</td>\n",
       "      <td>[excel, function, size, byte, return, file, si...</td>\n",
       "      <td>vba excel function for returning file size byt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[git, timezone, format, timestamp, timezone-of...</td>\n",
       "      <td>[git, timezone, timestamp, format, git, way, t...</td>\n",
       "      <td>git timezone and timestamp format from git can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[python, request, python-3.x, response, wsgi]</td>\n",
       "      <td>[wsgi, request, response, request, response, c...</td>\n",
       "      <td>wsgi request and response wrappers for python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[linux, unix, process, path, environment]</td>\n",
       "      <td>[path, process, linux, environment, path, proc...</td>\n",
       "      <td>how get the path process unix linux windows en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tags  \\\n",
       "0         [javascript, jquery, string, date, object]   \n",
       "1                 [vba, excel, function, size, byte]   \n",
       "2  [git, timezone, format, timestamp, timezone-of...   \n",
       "3      [python, request, python-3.x, response, wsgi]   \n",
       "4          [linux, unix, process, path, environment]   \n",
       "\n",
       "                                               Texts  \\\n",
       "0  [jquery, javascript, convert, date, string, da...   \n",
       "1  [excel, function, size, byte, return, file, si...   \n",
       "2  [git, timezone, timestamp, format, git, way, t...   \n",
       "3  [wsgi, request, response, request, response, c...   \n",
       "4  [path, process, linux, environment, path, proc...   \n",
       "\n",
       "                                           Sentences  \n",
       "0  jquery javascript convert date string date hav...  \n",
       "1  vba excel function for returning file size byt...  \n",
       "2  git timezone and timestamp format from git can...  \n",
       "3  wsgi request and response wrappers for python ...  \n",
       "4  how get the path process unix linux windows en...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa4d2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Tags       1000 non-null   object\n",
      " 1   Texts      1000 non-null   object\n",
      " 2   Sentences  1000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7e0c8",
   "metadata": {},
   "source": [
    "Le jeu de données est très important pour les temps de calculs à ma disposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af27a9c5",
   "metadata": {},
   "source": [
    "Je décide aussi de prendre les observations pour lesquelles la similarité entre les colonnes Texts et Tags est importante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9132303",
   "metadata": {},
   "source": [
    "Cela va me permettre de pouvoir regarder la pertinence des tags que mes modèles vont proposer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57967eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    jaccard_similarity = len(intersection) / len(union)\n",
    "    return jaccard_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331404ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_similarity_rows(data, col1, col2, n):\n",
    "    data[\"jaccard_similarity\"] = data.apply(lambda x: jaccard_similarity(x[col1], x[col2]), axis=1)\n",
    "    data = data.sort_values(by=\"jaccard_similarity\", ascending=False)\n",
    "    return data.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26749958",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = get_highest_similarity_rows(data, \"Tags\", \"Texts\", sample_size)\n",
    "data_sample = data_sample[['Tags', 'Texts', 'Sentences', 'jaccard_similarity']]\n",
    "data_sample.drop(['jaccard_similarity'], axis=1, inplace=True)\n",
    "data_sample.reset_index(inplace=True, drop=True)\n",
    "print(data_sample.shape)\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915892b1",
   "metadata": {},
   "source": [
    "Afin de mettre en place une méthode d’évaluation propre, je décide de séparer le jeu de données en deux parties : \n",
    " - la première me servira à l'entrainement des modèles\n",
    " - la seconde partie me permettra d'évaluer certains modèles sur des données qui leurs sont inconnues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1f899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_eval, \\\n",
    "tags_train, tags_eval, \\\n",
    "sentences_train, sentences_eval = train_test_split(\n",
    "    data_sample[\"Texts\"],\n",
    "    data_sample[\"Tags\"],\n",
    "    data_sample[\"Sentences\"],\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d311e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = texts_train.to_list()\n",
    "tags_list = tags_train.to_list()\n",
    "sentences = sentences_train.to_list()\n",
    "flat_texts = [\" \".join(text) for text in texts_list]\n",
    "flat_tags = [\" \".join(tag) for tag in tags_list]\n",
    "vocabulary_texts = list(set([word for item in texts_list for word in item]))\n",
    "vocabulary_tags = list(set([word for item in tags_list for word in item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c8269d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list_eval = texts_eval.to_list()\n",
    "tags_list_eval = tags_eval.to_list()\n",
    "sentences_eval = sentences_eval.to_list()\n",
    "flat_texts_eval = [\" \".join(text) for text in texts_list]\n",
    "flat_tags_eval = [\" \".join(tag) for tag in tags_list]\n",
    "vocabulary_texts_eval = list(set([word for item in texts_list for word in item]))\n",
    "vocabulary_tags_eval = list(set([word for item in tags_list for word in item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9ec2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in flat_tags:\n",
    "    words.extend(text.split())\n",
    "\n",
    "counter = Counter(words)\n",
    "top_200_tags = [word for word, count in counter.most_common(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2975b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in flat_tags_eval:\n",
    "    words.extend(text.split())\n",
    "\n",
    "counter = Counter(words)\n",
    "top_200_tags_eval = [word for word, count in counter.most_common(200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2b074",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_2\">2. Approche non supervisée</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883c387",
   "metadata": {},
   "source": [
    "### Étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "000d5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, jaccard_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import Nmf\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.matutils import corpus2dense\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8eb174",
   "metadata": {},
   "source": [
    "LDA (Latent Dirichlet Allocation) est une technique de topic modeling qui permet de découvrir les thèmes cachés (ou \"latents\") dans un ensemble de textes. Elle permet de regrouper des textes qui traitent des mêmes sujets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea29ec",
   "metadata": {},
   "source": [
    "La classe LdaModel de gensim est basée sur l'algorithme d'allocation latente de Dirichlet (LDA), qui est un modèle probabiliste génératif utilisé pour découvrir les sujets cachés dans un corpus de textes. La classe LatentDirichletAllocation de scikit-learn est également basée sur l'algorithme LDA, mais elle peut avoir des différences en termes d'implémentation, comme l'algorithme d'optimisation utilisé ou les paramètres disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea0e17",
   "metadata": {},
   "source": [
    "NMF (Non-negative Matrix Factorization) est une autre technique de topic modeling qui permet de décomposer une matrice document-terme en deux matrices de facteurs non-négatifs. Elle est souvent utilisée pour découvrir les thèmes cachés dans des textes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96332ae",
   "metadata": {},
   "source": [
    "La classe gensim Nmf est basée sur l'algorithme de factorisation de matrice non-négative, qui est différente de la classe NMF de scikit-learn, qui est basée sur la méthode de gradient projeté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35595bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_optimal_num_topics(data, vectorizer, n_topics_range, texts_list):\n",
    "    \"\"\"\n",
    "    Given data, a vectorizer, a range of number of topics to test,\n",
    "    and the list of texts, applies the models to the data and plots \n",
    "    the silhouette and coherence scores to help determine the optimal\n",
    "    number of topics.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data = vectorizer.fit_transform(data)\n",
    "    dictionary = Dictionary(texts_list)\n",
    "    corpus = [dictionary.doc2bow(txt) for txt in texts_list]\n",
    "\n",
    "    lda_scores = []\n",
    "    nmf_scores = []\n",
    "    coherence_nmf = []\n",
    "    coherence_lda = []\n",
    "\n",
    "    for n_topics in tqdm(n_topics_range, ascii=' >='):\n",
    "\n",
    "        # Calculate the silhouette score for the LDA model\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, \n",
    "                                        max_iter=1000)\n",
    "        lda.fit(data)\n",
    "        topic_assignments = lda.transform(data)\n",
    "        labels = np.argmax(topic_assignments, axis=1)\n",
    "        lda_scores.append(silhouette_score(topic_assignments, labels, \n",
    "                                           metric='euclidean'))\n",
    "\n",
    "        # Calculate the silhouette score for the NMF model\n",
    "        nmf = NMF(n_components=n_topics, max_iter=1000)\n",
    "        nmf.fit(data)\n",
    "        topic_assignments = nmf.transform(data)\n",
    "        labels = np.argmax(topic_assignments, axis=1)\n",
    "        nmf_scores.append(silhouette_score(topic_assignments, labels, \n",
    "                                           metric='euclidean'))\n",
    "\n",
    "        # Calculate the coherence score for the LDA model\n",
    "        lda = LdaModel(corpus, num_topics=n_topics, id2word=dictionary)\n",
    "        cm_lda = CoherenceModel(model=lda, texts=texts_list, \n",
    "                                dictionary=dictionary, coherence='c_v')\n",
    "        coherence_lda.append(cm_lda.get_coherence())\n",
    "\n",
    "        # Calculate the coherence score for the NMF model\n",
    "        nmf = Nmf(corpus, num_topics=n_topics, id2word=dictionary)\n",
    "        cm_nmf = CoherenceModel(model=nmf, texts=texts_list, \n",
    "                                dictionary=dictionary, coherence='c_v')\n",
    "        coherence_nmf.append(cm_nmf.get_coherence())\n",
    "\n",
    "    scores = pd.DataFrame(columns=['topics_silhouette',\n",
    "                                   'score_silhouette',\n",
    "                                   'topics_coherence',\n",
    "                                   'score_coherence'],\n",
    "                          index=['LDA', 'NMF'])\n",
    "\n",
    "    scores['topics_silhouette'] = [n_topics_range[np.argmax(lda_scores)], \n",
    "                                   n_topics_range[np.argmax(nmf_scores)]]\n",
    "    scores['score_silhouette'] = [max(lda_scores), max(nmf_scores)]\n",
    "    scores['topics_coherence'] = [n_topics_range[np.argmax(coherence_lda)], \n",
    "                                  n_topics_range[np.argmax(coherence_nmf)]]\n",
    "    scores['score_coherence'] = [max(coherence_lda), max(coherence_nmf)]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    plt.suptitle('Scores de Silhouette et de Coherence pour LDA et NMF avec {}'.format(str(vectorizer).split('(')[0]))\n",
    "    ax1.plot(n_topics_range, lda_scores, label='LDA')\n",
    "    ax1.plot(n_topics_range, nmf_scores, label='NMF')\n",
    "    ax1.set_xlabel('Number of Topics')\n",
    "    ax1.set_ylabel('Silhouette score')\n",
    "    ax1.legend()\n",
    "    ax2.plot(n_topics_range, coherence_lda, label='LDA')\n",
    "    ax2.plot(n_topics_range, coherence_nmf, label='NMF')\n",
    "    ax2.set_xlabel('Number of Topics')\n",
    "    ax2.set_ylabel('Coherence score')\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b21431fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of number of topics to test\n",
    "# n_topics_range = range(2, 22, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29c88abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of number of topics to test\n",
    "n_topics_range = range(2, 6, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537d01f",
   "metadata": {},
   "source": [
    "CountVectorizer() est une implémentation de l'approche bag-of-words pour la vectorisation de textes. Il convertit un ensemble de documents en un tableau de compte de mots (ou un sac de mots), où chaque ligne représente un document et chaque colonne représente un mot. Le nombre dans chaque cellule est le nombre de fois où le mot correspondant est présent dans le document correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09910832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|==========================================                                          | 1/2 [00:46<00:46, 46.57s/it]"
     ]
    }
   ],
   "source": [
    "models_CountVectorizer = determine_optimal_num_topics(flat_texts,\n",
    "                                                      CountVectorizer(),\n",
    "                                                      n_topics_range,\n",
    "                                                      texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a118024",
   "metadata": {},
   "source": [
    "TF-IDF (term frequency-inverse document frequency) est une technique utilisée pour pondérer les termes dans les textes en fonction de leur fréquence d'apparition. Elle permet de donner plus de poids aux termes qui apparaissent fréquemment dans un document mais rarement dans l'ensemble des documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_TfidfVectorizer= determine_optimal_num_topics(flat_texts,\n",
    "                                                     TfidfVectorizer(vocabulary=vocabulary_texts),\n",
    "                                                     n_topics_range,\n",
    "                                                     texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959aea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9623f",
   "metadata": {},
   "source": [
    "Le score de silhouette mesure la similarité d'un objet à son propre groupe par rapport aux autres groupes et généralement, plus il est proche de 1, meilleure est la classification. Le score de cohérence mesure à quel point les sujets sont \"interprétables par les humains\", généralement plus proche de 1, meilleur c'est."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1adfb6d",
   "metadata": {},
   "source": [
    "Dans notre situation, lorsque le nombre de sujets augmente, ils sont davantage \"interprétables par les humains\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a1e69",
   "metadata": {},
   "source": [
    "Nous devons maintenant essayer d'obtenir des tags en utilisant ces méthodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c78d4a",
   "metadata": {},
   "source": [
    "Je choisis d'utiliser uniquement LDA pour la suite car c'est la méthode qui obtient les meilleurs scores de silhouette."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee4d9b",
   "metadata": {},
   "source": [
    "Je choisis le nombre de topics au regard des résultats précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fa5a5",
   "metadata": {},
   "source": [
    "Le paramètre min_df définit le nombre minimum de documents dans lesquels un mot doit être présent pour être inclus dans le vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f264637",
   "metadata": {},
   "source": [
    "Le paramètre max_df définit la fréquence maximale d'un mot en pourcentage de tous les documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8132fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88064169",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_CV = CountVectorizer(vocabulary=vocabulary_texts, min_df=min_df, max_df=max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_TFIDF = TfidfVectorizer(vocabulary=vocabulary_texts, min_df=min_df, max_df=max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_from_text(texts_list, flat_texts, n_topics, vocabulary_texts, min_df, max_df):\n",
    "    pred_gensim = list()\n",
    "    pred_sklearn = list()\n",
    "    pred_tfidf = list()\n",
    "    pred_count = list()\n",
    "\n",
    "    # Predict tags using LdaModel (gensim) without bow or TF-IDF\n",
    "    dictionary = Dictionary(texts_list)\n",
    "    corpus = [dictionary.doc2bow(txt) for txt in texts_list]\n",
    "    lda = LdaModel(corpus, num_topics=n_topics, id2word=dictionary, random_state=42)\n",
    "    for text in tqdm(texts_list, ascii=' >='):\n",
    "        bow = dictionary.doc2bow(text)\n",
    "        topics = lda.get_document_topics(bow, minimum_probability=0)\n",
    "        topic_id, prob = max(topics, key=lambda x: x[1])\n",
    "        topic_words = [w for w, p in lda.show_topic(topic_id, topn=5)]\n",
    "        pred_gensim.append(topic_words)\n",
    "\n",
    "    # Predict tags using LDA (sklearn) without bow or TF-IDF\n",
    "    corpus_dense = corpus2dense(corpus, num_terms=len(dictionary)).T\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    lda.fit(corpus_dense)\n",
    "    for text in tqdm(texts_list, ascii=' >='):\n",
    "        bow = dictionary.doc2bow(text)\n",
    "        dense_bow = corpus2dense([bow], num_terms=len(dictionary)).T[0]\n",
    "        dense_bow = np.reshape(dense_bow, (1, -1))\n",
    "        topic_distribution = lda.transform(dense_bow)\n",
    "        topic_id = topic_distribution.argmax()\n",
    "        top_words_indices = np.argsort(-lda.components_[topic_id])[:5]\n",
    "        topic_words = [dictionary[i] for i in top_words_indices]\n",
    "        pred_sklearn.append(topic_words)\n",
    "\n",
    "    # Predict tags using LdaModel with TF-IDF\n",
    "    vectorizer = vectorizer_TFIDF\n",
    "    bow = vectorizer.fit_transform(flat_texts)\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    topics = lda.fit_transform(bow)\n",
    "    for i in tqdm(range(len(texts_list)), ascii=' >='):\n",
    "        topic_id = topics.argmax(axis=1)[i]\n",
    "        dense_bow_matrix = bow.toarray()\n",
    "        top_words_indices = dense_bow_matrix[i].argsort()[-5:][::-1]\n",
    "        topic_words = [list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(i)] for i in top_words_indices]\n",
    "        pred_tfidf.append(topic_words)\n",
    "\n",
    "    # Predict tags using LdaModel with CountVectorizer\n",
    "    vectorizer = vectorizer_CV\n",
    "    bow = vectorizer.fit_transform(flat_texts)\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    topics = lda.fit_transform(bow)\n",
    "    for i in tqdm(range(len(texts_list)), ascii=' >='):\n",
    "        topic_id = topics.argmax(axis=1)[i]\n",
    "        dense_bow_matrix = bow.toarray()\n",
    "        top_words_indices = dense_bow_matrix[i].argsort()[-5:][::-1]\n",
    "        topic_words = [list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(i)] for i in top_words_indices]\n",
    "        pred_count.append(topic_words)           \n",
    "\n",
    "    return pred_gensim, pred_sklearn, pred_tfidf, pred_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gensim, pred_sklearn, pred_tfidf, pred_count = get_tags_from_text(texts_list,\n",
    "                                                                       flat_texts,\n",
    "                                                                       n_topics,\n",
    "                                                                       vocabulary_texts,\n",
    "                                                                       min_df,\n",
    "                                                                       max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gensim[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sklearn[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcf1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tfidf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06b692",
   "metadata": {},
   "source": [
    "Il semblerait que les modèles avec CountVectorizer et TfidfVectorizer prédisent des tags assez similaires à ceux donnés par les utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9480618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags_list = [pred_gensim, pred_sklearn, pred_tfidf, pred_count]\n",
    "pred_names = [\"gensim\", \"sklearn\", \"tfidf\", \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=top_200_tags)\n",
    "tags_mlb = mlb.fit_transform(tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fa2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags_bin_list = [mlb.transform(pred_tags) for pred_tags in pred_tags_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(true_tags, pred_tags_bin_list, pred_names):\n",
    "    f1_scores = []\n",
    "    jaccard_scores = []\n",
    "    scoring_methods = [\"F1 Score\", \"Jaccard Score\"]\n",
    "    for pred_tags in pred_tags_bin_list:\n",
    "        f1_scores.append(f1_score(true_tags, pred_tags, average='samples'))\n",
    "        jaccard_scores.append(jaccard_score(true_tags, pred_tags, average='samples'))\n",
    "\n",
    "    metrics = {\"Jaccard\": jaccard_scores, \"F1\": f1_scores}\n",
    "    metrics_df = pd.DataFrame(metrics, index=pred_names)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    axes = axes.ravel()\n",
    "    for i, metric in enumerate(metrics.keys()):\n",
    "        sns.barplot(data=metrics_df, x=metrics_df.index, y=metric, ax=axes[i])\n",
    "        axes[i].set_ylabel('Score')\n",
    "        axes[i].set_title(scoring_methods[i])\n",
    "    plt.show()\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d0839",
   "metadata": {},
   "source": [
    " - F1 Score: mesure de l'exactitude d'un modèle, il est un moyen harmonique de précision et de rappel. Il varie de 0 à 1, où un score proche de 1 indique une meilleure performance et un score proche de 0 indique une performance moins bonne. \n",
    " - Jaccard Score: mesure de la similarité entre les deux ensembles de prédictions et de vraies étiquettes. Il varie de 0 à 1, où un score proche de 1 indique une très grande similitude et un score proche de 0 indique une grande dissimilarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(tags_mlb, pred_tags_bin_list, pred_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b5e1b",
   "metadata": {},
   "source": [
    "Nous observons de meilleurs scores avec un vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904348fb",
   "metadata": {},
   "source": [
    "### Résultats de l'étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9906ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1 & s2) / len(s1 | s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ddc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(true_tags, pred_tags):\n",
    "    scores = [jaccard_index(t, p) for t, p in zip(true_tags, pred_tags)]\n",
    "    mean_score = sum(scores) / len(scores)\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similar_tags(true_tags, pred_tags, method):\n",
    "    mean_score = calculate_scores(true_tags, pred_tags)\n",
    "    similar_counts = []\n",
    "    \n",
    "    for pred_tags, true_tags in zip(pred_tags, true_tags):\n",
    "        similar_words = set(pred_tags) & set(true_tags)\n",
    "        similar_counts.append(len(similar_words))\n",
    "\n",
    "    counter = Counter(similar_counts)\n",
    "    counter = dict(sorted(counter.items()))\n",
    "\n",
    "    # Add missing keys to counter with value 0\n",
    "    keys = set(range(0, 6))\n",
    "    missing_keys = keys - set(counter.keys())\n",
    "    for key in missing_keys:\n",
    "        counter[key] = 0\n",
    "    sorted_counter = dict(sorted(counter.items()))\n",
    "        \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    fig.suptitle(f\"Similarité des tags avec la méthode {method}\", fontsize=14, fontweight='bold', y=1.05)\n",
    "    axs[0].bar(sorted_counter.keys(), sorted_counter.values())\n",
    "    axs[0].set_xticks(range(0,6,1))\n",
    "    axs[0].set_xticklabels(sorted_counter.keys(), rotation=0)\n",
    "    axs[0].set_xlabel('Nombre de tags similaires', fontsize=11)\n",
    "    axs[0].set_ylabel(\"Nombre d'observations\", fontsize=11)\n",
    "    axs[0].set_title(\"Nombre d'observations avec un\\n nombre de tags similaires\", fontsize=12)   \n",
    "    axs[1].pie(sorted_counter.values(), labels=sorted_counter.keys(), autopct='%1.1f%%', pctdistance=0.8)\n",
    "    axs[1].legend(title='Tags\\nSimilaires', bbox_to_anchor=(1, 0.9), prop={'size': 8}, title_fontsize=10)\n",
    "    axs[1].set_title(\"Pourcentage d'observations avec \\n un nombre de tags similaires\", fontsize=12)\n",
    "    \n",
    "    textstr = ''.join((\n",
    "        r'Jaccard_index = %.2f' % (mean_score, )))\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    axs[1].text(0.8, 0, textstr, transform=axs[1].transAxes, fontsize=12,\n",
    "                verticalalignment='top', bbox=props)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099abbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(tags_list, pred_gensim, 'LDA Gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3384fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(tags_list, pred_sklearn, 'LDA Sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(tags_list, pred_tfidf, 'LDA + TFIDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(tags_list, pred_count, 'LDA + Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1a595",
   "metadata": {},
   "source": [
    "Les vectorizers apportent une réelle plus value avec davantage de tags prédis similaires aux tags originaux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350311f",
   "metadata": {},
   "source": [
    "### LDA + TF-IDF +  PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee25c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict tags using LdaModel with TF-IDF\n",
    "vectorizer = vectorizer_TFIDF\n",
    "bow = vectorizer.fit_transform(flat_texts)\n",
    "\n",
    "# Apply PCA to the TF-IDF matrix\n",
    "pca = PCA()\n",
    "pca_bow = pca.fit_transform(bow.toarray())\n",
    "\n",
    "# Calculate the explained variance\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot the explained variance\n",
    "axs[0].plot(np.cumsum(explained_variance))\n",
    "axs[0].set_xlabel(\"Number of Components\")\n",
    "axs[0].set_ylabel(\"Explained Variance (%)\")\n",
    "axs[0].axhline(y=0.90, linewidth=2, color='black')\n",
    "axs[0].text(2, 0.91, 'Seuil des 90% de variance', fontsize=14)\n",
    "\n",
    "# Scatter Plot of PCA Results\n",
    "axs[1].scatter(pca_bow[:, 0], pca_bow[:, 1])\n",
    "axs[1].set_xlabel(\"First Principal Component\")\n",
    "axs[1].set_ylabel(\"Second Principal Component\")\n",
    "axs[1].set_title(\"Scatter Plot of PCA Results\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_positive_pca(X):\n",
    "    pca = PCA(n_components=0.90)\n",
    "    X_transformed = pca.fit_transform(X)\n",
    "    if (X_transformed < 0).sum() > 0:\n",
    "        X_transformed -= X_transformed.min()\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88695d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_bow = ensure_positive_pca(bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef05847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict tags using LdaModel with CountVectorizer\n",
    "pred_tfidf_pca = list()\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "topics = lda.fit_transform(pca_bow)\n",
    "for i in tqdm(range(len(texts_list)), ascii=' >='):\n",
    "    topic_id = topics.argmax(axis=1)[i]\n",
    "    dense_bow_matrix = bow.toarray()\n",
    "    top_words_indices = dense_bow_matrix[i].argsort()[-5:][::-1]\n",
    "    topic_words = [list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(i)] for i in top_words_indices]\n",
    "    pred_tfidf_pca.append(topic_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e174a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(tags_list, pred_tfidf_pca, 'LDA + TFIDF + PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daac687",
   "metadata": {},
   "source": [
    "### LDA + CountVectorizer +  PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587eaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict tags using LdaModel with CountVectorizer\n",
    "vectorizer = vectorizer_CV\n",
    "bow = vectorizer_CV.fit_transform(flat_texts)\n",
    "\n",
    "# Apply PCA to the count matrix\n",
    "pca = PCA()\n",
    "pca_bow = pca.fit_transform(bow.toarray())\n",
    "\n",
    "# Calculate the explained variance\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a36d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot the explained variance\n",
    "axs[0].plot(np.cumsum(explained_variance))\n",
    "axs[0].set_xlabel(\"Number of Components\")\n",
    "axs[0].set_ylabel(\"Explained Variance (%)\")\n",
    "axs[0].axhline(y=0.90, linewidth=2, color='black')\n",
    "axs[0].text(2, 0.91, 'Seuil des 90% de variance', fontsize=14)\n",
    "\n",
    "# Scatter Plot of PCA Results\n",
    "axs[1].scatter(pca_bow[:, 0], pca_bow[:, 1])\n",
    "axs[1].set_xlabel(\"First Principal Component\")\n",
    "axs[1].set_ylabel(\"Second Principal Component\")\n",
    "axs[1].set_title(\"Scatter Plot of PCA Results\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34bf5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_bow = ensure_positive_pca(bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict tags using LdaModel with CountVectorizer\n",
    "pred_count_pca = list()\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "topics = lda.fit_transform(pca_bow)\n",
    "for i in tqdm(range(len(texts_list)), ascii=' >='):\n",
    "    topic_id = topics.argmax(axis=1)[i]\n",
    "    dense_bow_matrix = bow.toarray()\n",
    "    top_words_indices = dense_bow_matrix[i].argsort()[-5:][::-1]\n",
    "    topic_words = [list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(i)] for i in top_words_indices]\n",
    "    pred_count_pca.append(topic_words)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(tags_list, pred_count_pca, 'LDA + Count + PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65b6e3",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_3\">3. Approche supervisée</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ea923",
   "metadata": {},
   "source": [
    "### Étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfec925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18dac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb = MultiLabelBinarizer(classes=vocabulary_tags)\n",
    "# tags_mlb = mlb.fit_transform(flat_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab39b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=vocabulary_tags)\n",
    "tags_mlb = mlb.fit_transform(tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaae01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=top_200_tags)\n",
    "tags_mlb = mlb.fit_transform(tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(random_state=42, max_iter=300, tol=1e-5),\n",
    "               SGDClassifier(random_state=42, max_iter=300, tol=1e-5),\n",
    "               RandomForestClassifier(random_state=42),\n",
    "               KNeighborsClassifier(),\n",
    "               MultinomialNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_supervised_scores(flat_texts, tags_mlb, vectorizer, classifiers):\n",
    "\n",
    "    # Create an empty dataframe to store the results\n",
    "    results_df = pd.DataFrame(columns=['Classifier',\n",
    "                                       'F1 Score',\n",
    "                                       'Jaccard Score',\n",
    "                                       'Time (s)'])\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(flat_texts, tags_mlb, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Vectorize X_train and X_test\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # Fit an independent model for each class using the OneVsRestClassifier wrapper.\n",
    "    for classifier in tqdm(classifiers, ascii=' >='):\n",
    "        start_time = time.time()\n",
    "        ovrc = OneVsRestClassifier(classifier)\n",
    "        ovrc.fit(X_train, y_train)\n",
    "        y_pred_ovrc = ovrc.predict(X_test)\n",
    "        end_time = time.time()\n",
    "\n",
    "        f1 = round(f1_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        jaccard = round(jaccard_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        time_taken = round(end_time - start_time, 4)\n",
    "\n",
    "        results_df = results_df.append({'Classifier': str(classifier).split('(')[0], \n",
    "                                        'F1 Score': f1,\n",
    "                                        'Jaccard Score': jaccard,\n",
    "                                        'Time (s)': time_taken},\n",
    "                                        ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da67f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_CountVectorizer = calculate_supervised_scores(flat_texts,\n",
    "                                                      tags_mlb,\n",
    "                                                      vectorizer_CV,\n",
    "                                                      classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa632ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results_df):\n",
    "    \n",
    "    # Create a figure with 5 subplots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    # Set a color palette\n",
    "    my_palette = sns.color_palette(\"husl\", 5)\n",
    "\n",
    "    # Set the x-axis to be a range of numerical values\n",
    "    x = range(len(results_df))\n",
    "    scoring_methods = ['F1 Score', 'Jaccard Score', 'Time (s)']\n",
    "\n",
    "    # Create a subplot for each scoring method\n",
    "    for i, scoring_method in enumerate(scoring_methods):\n",
    "        sns.barplot(x='Classifier', \n",
    "                    y=scoring_method, \n",
    "                    data=results_df, \n",
    "                    ax=axs[i], \n",
    "                    palette=my_palette, \n",
    "                    label=scoring_method)\n",
    "\n",
    "    # Add classifier names to x-axis\n",
    "    for i in range(3):\n",
    "        axs[i].set_title(scoring_methods[i])\n",
    "        axs[i].set_xticks(x)\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].set_ylabel('Score')\n",
    "        axs[i].set_xticklabels(results_df['Classifier'], rotation=90)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df082fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_TfidfVectorizer = calculate_supervised_scores(flat_texts,\n",
    "                                                      tags_mlb,\n",
    "                                                      vectorizer_TFIDF,\n",
    "                                                      classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6aede",
   "metadata": {},
   "source": [
    "Le SGDClassifier obtient les meilleurs scores, peu importe le vectorizer utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07480ac",
   "metadata": {},
   "source": [
    "Le modèle avec RandomForestClassifier nécessite un temps d'entraînement très long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639f59c",
   "metadata": {},
   "source": [
    "Selon ces résultats, il semble que le SGDClassifier ait les meilleures performances globales.  Les classificateurs de types MultinomialNB et LogisticRegression se comportent également bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206e313",
   "metadata": {},
   "source": [
    "### LogisticRegression + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b10da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR = pd.DataFrame(columns=['F1 Score', 'Jaccard Score'])\n",
    "results_LR = results_LR.append(results_CountVectorizer.iloc[0, 1:]).reset_index(drop=True)\n",
    "results_LR = results_LR.append(results_TfidfVectorizer.iloc[0, 1:]).reset_index(drop=True)\n",
    "results_LR['Classifier'] = ['CountVectorizer', 'TfidfVectorizer']\n",
    "results_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ffcd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849f05e",
   "metadata": {},
   "source": [
    "CountVectorizer permet d'avoir des performances légèrement supérieure à TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_LR = LogisticRegression(random_state=42, max_iter=300, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_LR = {'estimator__C': [0.01, 0.1, 0.01],\n",
    "                 'estimator__penalty': ['l1', 'l2'],\n",
    "                 'estimator__solver': ['lbfgs', 'liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_supervised_scores(flat_texts, tags_mlb, vectorizer, classifier, parameters):\n",
    "    results_df = pd.DataFrame(columns=['Classifier', 'F1 Score', 'Jaccard Score', 'Time (s)'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(flat_texts, tags_mlb, test_size=0.2, random_state=42)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    ovrc = OneVsRestClassifier(classifier)\n",
    "    clf = GridSearchCV(ovrc, parameters, cv=5, verbose=2)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    best_params = clf.best_params_ if hasattr(clf, 'best_params_') else None\n",
    "    \n",
    "    f1 = round(f1_score(y_test, y_pred, average='samples'), 4)\n",
    "    jaccard = round(jaccard_score(y_test, y_pred, average='samples'), 4)\n",
    "    time_taken = round(end_time - start_time, 4)\n",
    "    \n",
    "    results_df = results_df.append({'Classifier': str(classifier).split('(')[0], \n",
    "                                    'F1 Score': f1,\n",
    "                                    'Jaccard Score': jaccard,\n",
    "                                    'Time (s)': time_taken},\n",
    "                                    ignore_index=True)\n",
    "    return results_df, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR, best_params_LR = calculate_supervised_scores(flat_texts,\n",
    "                                                         tags_mlb,\n",
    "                                                         vectorizer_CV,\n",
    "                                                         classifier_LR,\n",
    "                                                         parameters_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecfa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5776b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7416ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229fafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f4ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19a09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98271251",
   "metadata": {},
   "source": [
    "### SGDClassifier + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cdc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_SGD = pd.DataFrame(columns=['F1 Score', 'Jaccard Score'])\n",
    "results_SGD = results_SGD.append(results_CountVectorizer.iloc[1, 1:]).reset_index(drop=True)\n",
    "results_SGD = results_SGD.append(results_TfidfVectorizer.iloc[1, 1:]).reset_index(drop=True)\n",
    "results_SGD['Classifier'] = ['CountVectorizer', 'TfidfVectorizer']\n",
    "results_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f267676",
   "metadata": {},
   "source": [
    "CountVectorizer permet d'avoir des performances légèrement supérieure à TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_SGD = SGDClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_SGD = {'estimator__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "                  'estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "                  'estimator__penalty': ['l1', 'l2', 'elasticnet']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53649557",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_SGD, best_params_SGD = calculate_supervised_scores(flat_texts,\n",
    "                                                           tags_mlb,\n",
    "                                                           vectorizer_TFIDF,\n",
    "                                                           classifier_SGD,\n",
    "                                                           parameters_SGD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65911bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_CountVectorizer[results_CountVectorizer['Classifier']=='SGDClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_CV = pd.concat([results_CountVectorizer[results_CountVectorizer['Classifier']=='SGDClassifier'],\n",
    "                        results_SGD])\n",
    "results_CV.iloc[1,0] = 'SGDClassifier_CV'\n",
    "results_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plot_results function\n",
    "plot_results(results_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0493063",
   "metadata": {},
   "source": [
    "Le modèle a bien pu être amélioré par Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bdeb01",
   "metadata": {},
   "source": [
    "### Résultats de l'étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ff0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {key.replace('estimator__', ''): value for key, value in best_params_SGD.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SGDClassifier(random_state=42, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9409554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovrc = OneVsRestClassifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flat_texts, tags_mlb, test_size=0.2, random_state=42)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "ovrc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_tags(text, vectorizer, mlb, classifier):\n",
    "    X = vectorizer.transform([text])\n",
    "    scores = classifier.decision_function(X)\n",
    "    top_5 = scores.argsort(axis=1)[:, :5][::-1]\n",
    "    top_5_tags = [mlb.classes_[i] for i in top_5.flatten()]\n",
    "    return top_5_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15058e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_SGDC = []\n",
    "for text in tqdm(flat_texts_eval):\n",
    "    top_5_tags = get_top_5_tags(text, vectorizer, mlb, ovrc)\n",
    "    tags_SGDC.append(top_5_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa140b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_tags_eval[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b14fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_SGDC[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(tags_list_eval, tags_SGDC, 'Count + SGDClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb7c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8bbff03",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_4\">4. Approche supervisée avec Word Embedding : Word2Vec</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea48f5",
   "metadata": {},
   "source": [
    "### Dataset d'essais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc479b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts_list,\n",
    "                                                    tags_mlb,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b0888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model on your text data\n",
    "w2v_model = Word2Vec(X_train, vector_size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary of only the words in the text data that are in the word2vec model\n",
    "vocab = set(w2v_model.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the text data to only include words in the vocabulary\n",
    "X_train = [[word for word in sublist if word in vocab] for sublist in X_train]\n",
    "X_test = [[word for word in sublist if word in vocab] for sublist in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2097c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any observations that have no words in the vocabulary\n",
    "train_removed_indexes = []\n",
    "test_removed_indexes = []\n",
    "for i, sublist in enumerate(X_train):\n",
    "    if not any(word in vocab for word in sublist):\n",
    "        train_removed_indexes.append(i)\n",
    "for i, sublist in enumerate(X_test):\n",
    "    if not any(word in vocab for word in sublist):\n",
    "        test_removed_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [x for i, x in enumerate(X_train) if i not in train_removed_indexes]\n",
    "X_test = [x for i, x in enumerate(X_test) if i not in test_removed_indexes]\n",
    "y_train = [x for i, x in enumerate(y_train) if i not in train_removed_indexes]\n",
    "y_test = [x for i, x in enumerate(y_test) if i not in test_removed_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for train and test data\n",
    "X_train_embedded = [np.mean([w2v_model.wv[word] for word in sentence], axis=0) for sentence in X_train]\n",
    "X_test_embedded = [np.mean([w2v_model.wv[word] for word in sentence], axis=0) for sentence in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(random_state=42, max_iter=300, tol=1e-5),\n",
    "               SGDClassifier(random_state=42, max_iter=300, tol=1e-5),\n",
    "               RandomForestClassifier(random_state=42),\n",
    "               KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f849d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_supervised_word2vec(X_train, X_test, y_train, y_test, classifiers):\n",
    "\n",
    "    # Create an empty dataframe to store the results\n",
    "    results_df = pd.DataFrame(columns=['Classifier',\n",
    "                                       'F1 Score', 'Jaccard Score', 'Time (s)'])\n",
    "\n",
    "    # Fit an independent model for each class using the OneVsRestClassifier wrapper.\n",
    "    for clf in classifiers:\n",
    "        start_time = time.time()\n",
    "        ovrc = OneVsRestClassifier(clf)\n",
    "        ovrc.fit(X_train, y_train)\n",
    "        y_pred_ovrc = ovrc.predict(X_test)\n",
    "        end_time = time.time()\n",
    "\n",
    "        f1 = round(f1_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        jaccard = round(jaccard_score(y_test, y_pred_ovrc, average='samples'), 4)\n",
    "        time_taken = round(end_time - start_time, 4)\n",
    "\n",
    "        results_df = results_df.append({'Classifier': str(clf).split('(')[0],\n",
    "                                        'F1 Score': f1,\n",
    "                                        'Jaccard Score': jaccard,\n",
    "                                        'Time (s)': time_taken},\n",
    "                                        ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256504e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_word2vec = calculate_supervised_word2vec(X_train_embedded,\n",
    "                                                    X_test_embedded,\n",
    "                                                    y_train,\n",
    "                                                    y_test,\n",
    "                                                    classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc654154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plot_results function\n",
    "plot_results(results_df_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bee59c",
   "metadata": {},
   "source": [
    "### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f2247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a91f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74734179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ccdd5b",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_5\">5. Approche supervisée avec Word Embedding : BERT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b99384",
   "metadata": {},
   "source": [
    "### Étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import tokenization\n",
    "from transformers import BertTokenizer, AutoModel, BertTokenizerFast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch import nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54798c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_sample['Texts'].copy()\n",
    "tags = data_sample['Tags'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "    texts[i] = \" \".join(texts[i])\n",
    "    tags[i] = \" \".join(tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a198200",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "tags_list = tags.to_list()\n",
    "tags_bin = mlb.fit_transform(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23821031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlb = MultiLabelBinarizer()\n",
    "# tags_list = tags.to_list()\n",
    "# tags_bin = mlb.fit_transform(tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23dcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(texts,\n",
    "                                                                    tags_bin,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b096e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "\n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "\n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "\n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "\n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "\n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = bert_encode(train_text.values, tokenizer, max_len=100)\n",
    "tokens_test = bert_encode(test_text.values, tokenizer, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(clf_output)\n",
    "    out = Dense(len(train_labels[0]), activation='sigmoid')(clf_output)\n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(Adam(learning_rate=2e-6), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e45cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(bert_layer, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94235bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a866b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0582987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one-hot encoded labels for training\n",
    "train_history = model.fit(\n",
    "    tokens_train, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f822087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x=np.arange(1, 11), y=train_history.history['loss'], label=\"Training Loss\", ax=axs[0])\n",
    "sns.lineplot(x=np.arange(1, 11), y=train_history.history['val_loss'], label=\"Validation Loss\", ax=axs[0])\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xticks(np.arange(1, 11))\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "\n",
    "sns.lineplot(x=np.arange(1, 11), y=train_history.history['binary_accuracy'], label=\"Training Accuracy\", ax=axs[1])\n",
    "sns.lineplot(x=np.arange(1, 11), y=train_history.history['val_binary_accuracy'], label=\"Validation Accuracy\", ax=axs[1])\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xticks(np.arange(1, 11))\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(tokens_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    preds = model.predict(bert_encode(text, tokenizer, max_len=100))\n",
    "    indices = np.argsort(preds)[0][-5:]\n",
    "    preds[0, indices] = 1\n",
    "    preds[np.where(preds != 1)] = 0\n",
    "    decoded = mlb.inverse_transform(preds)\n",
    "    \n",
    "    predictions.append(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af59b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[7:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97feddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tags(row):\n",
    "    tags = row.split()\n",
    "    tags = [f\"'{tag}'\" for tag in tags]\n",
    "    return tuple(tags)\n",
    "\n",
    "\n",
    "converted_tags = tags.apply(convert_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_tags[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ea318",
   "metadata": {},
   "source": [
    "### Résultats de l'étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(converted_tags, predictions, 'BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddef9c4",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_6\">6. Approche supervisée avec Sentence Embedding : USE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd835c",
   "metadata": {},
   "source": [
    "### Étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bab45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use = pd.read_csv(main_path+'saved_ressources/'+'data_cleaned_wo_tokenizer.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51553ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data_use['Texts'].to_list()\n",
    "tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a96566",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_sentences = [sentences[i] for i in saved_indexes]\n",
    "extracted_tags = [tags_list[i] for i in saved_indexes]\n",
    "parsed_true_tags = [ast.literal_eval(tags[1:-1]) for tags in extracted_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(input_text):\n",
    "    # Load the USE model\n",
    "    model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    all_keywords = []\n",
    "    # Encode all the sentences in the input text\n",
    "    embeddings = model(input_text)\n",
    "    # Compute the cosine similarity between all the sentences\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    # Iterate over the list of sentences\n",
    "    for i in range(len(input_text)):\n",
    "        # Find the most similar sentences\n",
    "        most_similar = np.argsort(-similarity_matrix[i])[1:6]\n",
    "        # Combine the most similar sentences with the current sentence\n",
    "        text = ' '.join([input_text[j] for j in most_similar])\n",
    "        # Extract the keywords from the combined text using RAKE\n",
    "        keyword_extractor = Rake()\n",
    "        keyword_extractor.extract_keywords_from_text(text)\n",
    "        word_degrees = keyword_extractor.get_word_degrees()\n",
    "        sorted_word_degrees = sorted(word_degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "        keywords = [word for word, degree in sorted_word_degrees[:5]]\n",
    "        all_keywords.append(keywords)\n",
    "    return all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = extract_keywords(extracted_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055932cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_true_converted_tags = [list(tag) for tag in parsed_true_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8fda65",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_true_converted_tags[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca7557",
   "metadata": {},
   "source": [
    "### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tags(parsed_true_converted_tags, keywords, 'USE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c1f6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa650af",
   "metadata": {},
   "source": [
    "2èpme approche USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_layer = hub.KerasLayer(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3352738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_encode(texts, max_len=512):\n",
    "    return np.array(use_layer(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf928de",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_train = use_encode(train_text.values, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_test = use_encode(test_text.values, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(use_layer, max_len=512):\n",
    "    input_text = Input(shape=(None,), dtype=tf.string, name=\"input_text\")\n",
    "    embedding = use_layer(input_text)\n",
    "    dense = Dense(128, activation='relu')(embedding)\n",
    "    out = Dense(len(train_labels[0]), activation='sigmoid')(dense)\n",
    "    model = Model(inputs=input_text, outputs=out)\n",
    "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(use_layer, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(use_train, train_labels, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a190d",
   "metadata": {},
   "source": [
    "## <font color=\"#114b98\" id=\"section_7\">7. Choix du modèle pour le code final à déployer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c244176",
   "metadata": {},
   "source": [
    "Nous allons maintenant comparer les différents modèles à l'aide de leurs résultats sur le dataset de tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf14c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589e1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a91f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6979e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b2567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35568c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643ec06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca872b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
